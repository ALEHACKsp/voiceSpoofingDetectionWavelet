\section{Short Review Notes}
\label{sec:revBibli}
\par When speech is replayed through a playback device, or recorded on a recording device, its frequency attributes change, as observed in paper \cite{np2}. This was also noted by the authors of paper \cite{Ren2019}, where a procedure to distinguish between regular speech and that coming from a reproductive device is presented. The specific focus of those analyses resides on the distortion caused by the loudspeakers, according to the energy and additional features from the signal spectrum. This certainly stimulates a refined spectral investigation, providing a clue for the solution we propose in Section \ref{sec:propApproach}. 
\\
\par As shown in paper \cite{7802552}, replayed speech can be detected by means of a scattering decomposition based on \textit {wavelets} and cepstral coefficients (SCCs), where feature vectors are assessed with Gaussian Mixture Models (GMM). Accordingly, in paper \cite{alluri2019replay}, the authors use zero-time windowing (ZTW) to, in conjunction with the cepstral analysis from the speech spectrum, detect replayed speech.	For both papers, spectral analysis plays a relevant role in characterizing the effects introduced by the recording and playback devices.
\\
\par Proceeding, in paper \cite{8725688}, a difference between the spectral properties of the original speech and the replayed one, which was based on cepstral coefficients from SAS2017 speech dataset, was detected. In the same direction, the proposal found in paper \cite{Hanilci2018} corresponds to the applications of residual linear prediction signals to, together with cepstral coefficients, create features that were associated with a GMM classifier, prominently detecting replayed speech from a refined spectral analysis.	
\\
\par For the detection of \textit{playback speech}, the authors of paper \cite{ISI:000473343500086} imported the concept of textures from image processing research. Local binary standards (LBP) and their respective histograms were used to produce feature vectors that were assessed by an SVM, once again focusing on the spectral analysis. An approach that combines speech signal analysis using \textit{Constant Q Transform} (CQT) with cepstral processing was shown in paper \cite{TODISCO2017516}. That technique results in what is called \textit{Cepstral Constant Q Coefficients} (CQCCs). According to the authors, the advantage of those coefficients resides on the resolution of the time-frequency distribution that was used as an input to two GMMs, each one trained by using either genuine or spoofed data.
\\
\par In paper \cite{Patel2015}, the Auditory Transformation (TU), which is based on wavelets and on the Hilbert Transform \cite{johansson1999hilbert} \cite{kschischang2006hilbert}, was used as input, together with Cochlear Filter Cepstral Coefficients (CFCC), to define an instantaneous frequency estimation (IF) operator. The whole process aims to emulate the way the human ear simultaneous interprets different frequency bands, being successfully applied to playback speech detection. Accordingly, the authors of paper \cite{ISI:000490497200068} propose a solution to distinguish genuine speech signals from spoofed ones by using reverberation and the unvoiced parts of speech, which contain a rich spectral and noise-like information. Combined with three GMMs, that technique succeed in the detection of playback speech.	
\\		
\par The main idea advocated by the authors of paper \cite{ISI:000465363900136} is to capture instantaneous amplitudes from spectral energy fluctuations to distinguish between genuine and spoofed speech. According to the authors, amplitude modulations are more susceptible to the noise inserted in the original signal by a recording device. In the same sense, the authors of paper \cite{ISI:000465363900139} state that specific frequency band differences can be used to distinguish between a legitimate signal and replayed speech. In particular, \textit{linear prediction in frequency domain} (FDLP) was proposed together with GMMs to successfully classify those data.
\\
\par In paper \cite{Suthokumar2018}, the authors propose two features that aim to interpret the static and dynamic components of speech signals, complementing the time-restricted characteristics found in the spectrum and allowing for genuine speech to be differentiated from spoofed data. The features, i.e., Modulation Spectral Centroid Frequency and Long Term Spectral Average, combined with a GMM, were successfully applied to the proposed task, confirming the important role of spectral analysis. Considering the enveloping of instantaneous amplitudes and frequencies in each narrow band filtered, the authors of paper \cite{ISI:000458728700054} also show how to differentiate a legitimate speech signal from a spoofed one in association with a GMM classifier.
\\
\par In paper \cite{ISI:000392503100008}, the application of Gammatone Frequency Cepstral Coefficients (MGFCC) was proposed by the authors. Gammatone is the product of a gamma distribution with a sinusoidal signal, being useful in the construction of auditory filters which, in that case, are used for feature extraction from speech signals. Together with a GMM, the proposed solution was successfully tested to the detection of replayed speech. In accordance, the authors of paper \cite{8396208} presented the Locus Sensitive Hashing (LSH), which had been frequently used as a classifier for problems related to big data. Combining it with MFCCs coefficients, genuine and spoofed speech were efficiently distinguished.	
\\
\par Despite the use of \textit{wavelets} in papers \cite{Patel2015} and \cite{7802552}, we highlight that, currently, their applications are scarce in the context of voice spoofing. In one of the most original approaches, i.e., the one described in \cite{ISI:000490497200068}, which inspects the unvoiced parts of speech signals, wavelet or wavelet-packets were not used. In that paper, and in most of those referenced above \cite{Hanilci2018} \cite{Patel2015} \cite{8396208} \cite{8725688} \cite{ISI:000490497200068}, Mel Scale is combined with another technique to define the voice spoofing detection strategy. Nevertheless, none of those publications used the Bark Scale, which was, surprisingly, the one that showed the best results in the specific case of this paper. Instead, the applications of cepstral coefficients combined with other techniques, such as GMMs, was very common \cite{alluri2019replay} \cite{7802552} \cite{8725688} \cite{Hanilci2018} \cite{TODISCO2017516} \cite{Patel2015} \cite{ISI:000392503100008}. In opposition, the proposed approach presents relevant results based just on two modest classifiers: Euclidean / Manhattan distances, and SVM.
\\
\par All the papers reviewed in this section focus on finding better feature vectors, however, none of them described quantitative strategies to assess their viability. Contrary to this, PFE was used in this paper to find the best feature combination. In terms of results, most of those papers, due to the use of \textit{SAS} \cite{SAS2015} \cite{SAS2017} \cite{SAS2019}  and \textit{AVspoof} \cite{AVspoof2015} databases, presented their results as a function of Equal Error Rate (EER) curves, whereas a few other adopted confusion matrices and  values of accuracy \cite{Ren2019} \cite{ISI:000473343500086} \cite{8396208}. In this paper, all the aforementioned metrics were considered, allowing for the establishment of an interesting set of metrics for comparisons. Therefore, to the best of our knowledge, a relevant contribution is provided in this paper. 
