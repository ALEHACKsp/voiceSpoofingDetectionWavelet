\section{Bibliographic review}
\label{sec:revBibli}

	\par In the article \cite{Ren2019}, a differentiation scheme between common speech and that coming from a reproductive device was presented. The focus of the analysis was on the distortion caused by the loudspeaker, according to the energy and other various characteristics of the signal spectrum.

	\par In \cite{DiqunYan2019} a method is shown to differentiate the voice of a true speaker from the voice generated by systems using synthesizers based on the \textit{hidden Markov model} (HMM).
		
	\par Using a scattering decomposition based on \textit {wavelets} and converting the result to cepstral coefficients (SCCs), the article \cite{7802552} contains the description of a feature vector that is evaluated by Gaussian Mixture Models (GMM) for purposes of \textit{playback speech detection}.	

	\par In \cite{alluri2019replay}, the authors use \textit{zero time windowing} or zero time windowing (ZTW) to, in conjunction with the cepstral analysis of the generated spectrum, do the analysis of the voice signals.	

	\par In \cite{8725688}, a difference was recorded between the spectral properties of the original voice and the recorded voice, which can be expressed by means of cepstral coefficients. A GMM was used as a classifier and the database used was SAS 2017.

	\par The proposal of the article \cite{Hanilci2018} was to use residual linear prediction signals to, together with cepstral coefficients, create characteristics that were presented to a GMM classifier.	

	\par For the detection of \textit{playback speech}, the authors of the article \cite{ISI:000473343500086} imported the texture concept for voice processing from the image processing area. Local binary standards (LBP) and their respective histograms were used to construct the characteristic vector that was evaluated by an SVM.
	
	\par An approach that combines speech signal analysis using \textit{Constant Q Transform} (CQT) with cepstral processing was shown in the article \cite{TODISCO2017516}. This technique results in what is called \textit{Cepstral Constant Coefficients Q} (CQCCs). According to the article, the advantage of these coefficients is the resolution of the variable time spectrum. In the case of classifiers, two GMMs were used, each trained using genuine and spoofed data respectively.

	\par In the article \cite{Patel2015} the \textit{Auditory Transformation (TU)}, which is based on the \textit{wavelet} transform, is used together with \textit{Cochlear Filter Cepstral Coefficients (CFCC)} which is the junction of cited methods plus an average of the values in a defined window interval. In addition, the \textit{instantaneous frequency estimation (IF)}, which is based on the Hilbert Transform \cite{johansson1999hilbert} \cite{kschischang2006hilbert}, is defined. The whole process aims to emulate natural mechanisms that occur inside the ear,  it uses, in addition to \textit{TU}, the calculation of cepstral coefficients and cosine transformation. For the composition of the feature vectors, the \textit{MFCC}, \textit{CFCC}, \textit{CFCC+IF} techniques were combined.
	
	\par The article \cite{ISI:000490497200068} proposes a solution to distinguish genuine voice signals from those spoofed using reverberation and the unvoiced parts of speech. Three GMMs were defined for the classification, in this strategy they vote whether or not an occurrence is true, always winning the classification that obtains the most votes.	
		
	\par The main idea behind the article \cite{ISI:000465363900136} was to capture the instantaneous amplitude from energy fluctuations to distinguish between genuine and spoofed voice signals. According to the authors, amplitude modulations are more susceptible to the noise inserted in the original signal by a recording device.

	\par In the work \cite{ISI:000465363900139}, specific frequency bands differences were used to distinguish between a legitimate signal and one used in counterfeiting attacks. In particular, \textit{linear prediction in frequency domain} (FDLP) was proposed together with GMMs to classify the data.
	
	\par In the article \cite{Suthokumar2018}, the authors proposed two new characteristics that aim to interpret the static and dynamic components of the signal, complementing the time-restricted characteristics in the spectrum, to distinguish between genuine and spoofed phrases. They are the \textit{Modulation Spectral Centroid Frequency} and the \textit{Long Term Spectral Average}. The system uses a GMM as a classifier.
	
	\par Considering the enveloping of instantaneous amplitudes and frequencies in each narrow band filtered, the authors of the article \cite{ISI:000458728700054} discussed how to differentiate a legitimate voice signal from a spoofed one. GMM was chosen as the classifier.

	\par In the scientific article \cite{ISI:000392503100008}, the use of \textit{gammatone frequency cepstral coefficients} (MGFCC) was proposed. Gammatone is the product of a gamma distribution with a sinusoidal signal and is used in the construction of auditory filters which, in this case, are used to extract characteristics from the voice signal. The classifier used was a GMM.
	
	\par According to the article \cite{8396208}, the \textit{locus} sensitive \textit{hashing} (LSH), which is often used as a classifier for problems related to \textit{big data}, has been combined with MFCCs coefficients for distinction between genuine and spoofed phrases. In the method, the MFCCs were extracted from the signal files for later application of the LSH, thus generating a \textit{hash} table. These \textit{hash} values were then compared, thus identifying the speaker.	
	
	\par Despite the use of \textit{wavelets} in the articles \cite{DiqunYan2019}, \cite{Patel2015} and \cite{7802552} it is interesting to note, at least until now, that their use is scarce in \textit{voice spoofing}. In one of the most original approaches, for example, the one explained in \cite{ISI:000490497200068} which uses the unvoiced parts of the signal, it would be very useful to use the \textit{wavelet} or \textit{wavelet packet} transforms. Both in this document and in most of the references used, it is common to use a \textit{MEL} scale combined with other techniques to construct the \textit{voice spoofing} detection method \cite{Hanilci2018}, \cite{Patel2015} , \cite{8396208}, \cite{8725688}, \cite{ISI:000490497200068}. However, none of these publications used the \textit{BARK} scale, which was, surprisingly, the one that showed the best results in the specific case of this dissertation. The use of cepstral coefficients combined with other techniques was very common \cite{alluri2019replay}, \cite{7802552}, \cite{8725688}, \cite{Hanilci2018}, \cite{TODISCO2017516}, \cite{Patel2015}, \cite{ISI:000392503100008}. Once the methods of generating the characteristic vectors were chosen, varied classifiers were selected, with emphasis on the relatively simple \textit{Gaussian Mixture Models} (GMM), the most chosen. This work also includes two modest classifiers: Euclidean/Manhattan distance and Support Vector Machine.

	\par Reading the mentioned articles in this section also indicates that, apparently, within the context of \textit{voice spoofing}, the effort is to create increasingly better feature vectors, being curious that in none of the consulted writings there was a methodology for comparison results other than the manual. In this dissertation, there are a number of candidate methods for generating feature vectors based on \textit{wavelets} and the \textit{BARK} and \textit{MEL} scales. Such applications were evaluated according to the paraconsistent engineering of characteristics that selected the best combination among the presented options. In terms of results, most studies, due to the use of the \textit{SAS} \cite{SAS2015} \cite{SAS2017} \cite{SAS2019}  and \textit{AVspoof} \cite{AVspoof2015} bases, presented their results according to the \textit {Equal Error Rate (EER)}, which is the standard measure for evaluation . Some others used only the accuracy \cite{8396208}, \cite{ISI:000473343500086}, \cite{DiqunYan2019}, \cite{Ren2019} and measures calculated in confusion tables. In this work, all the aforementioned metrics were considered.	
