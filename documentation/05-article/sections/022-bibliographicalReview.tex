\section{Bibliographic review}
\label{sec:revBibli}

	\par In the article \cite{Ren2019}, a differentiation scheme between common speech and that coming from a reproductive device was presented. The focus of the analysis was on the distortion caused by the loudspeaker, according to the energy and other various characteristics of the signal spectrum.

	\par In \cite{DiqunYan2019} a method is shown to differentiate the voice of a true speaker from the voice generated by systems using synthesizers based on the \textit{hidden Markov model} (HMM).
		
	\par Using a scattering decomposition based on \textit {wavelets} and converting the result to cepstral coefficients (SCCs), the article \cite{7802552} contains the description of a feature vector that is evaluated by Gaussian Mixture Models (GMM) for purposes of \textit{playback speech detection}.	

	\par In \cite{alluri2019replay}, the authors use \textit{zero time windowing} or zero time windowing (ZTW) to, in conjunction with the cepstral analysis of the generated spectrum, do the analysis of the voice signals.	

	\par In \cite{8725688}, a difference was recorded between the spectral properties of the original voice and the recorded voice, which can be expressed by means of cepstral coefficients. A GMM was used as a classifier and the database used was SAS 2017.

	\par A proposta do artigo \cite{Hanilci2018} foi usar sinais residuais de predição linear para, juntamente com coeficientes cepstrais, criar características que foram apresentas a um classificador GMM. Novamente, a base de dados usada foi a SAS 2015 e os resultados em ERR geral foram de 5,249.
	
	\par The proposal of the article \cite{Hanilci2018} was to use residual linear prediction signals to, together with cepstral coefficients, create characteristics that were presented to a GMM classifier.	

	\par For the detection of \textit{playback speech}, the authors of the article \cite{ISI: 000473343500086} imported the texture concept for voice processing from the image processing area. Local binary standards (LBP) and their respective histograms were used to construct the characteristic vector that was evaluated by an SVM.
	
	\par Uma abordagem que combina análise de sinal de fala usando a \textit{Transformada Constante Q} (CQT) com o processamento cepstral foi mostrada no artigo \cite{TODISCO2017516}. Essa técnica resulta no que se chama \textit{Coeficientes Cepstrais de Constante Q}(CQCCs). Segundo o artigo, a vantagem desses coeficientes é a resolução de espectro temporal variável. As bases de dados usadas foram a RedDots \cite{redDots}, SAS 2015 e AVSpoof 2015 \cite{AVSpoof2015}. Em se tratando de classificadores foram usados dois GMMs, cada um treinado usando os dados genuínos e \textit{spoofing} respectivamente. Os testes realizados para cada uma das bases chegou aos seguintes resultados: SAS 2015 $\rightarrow$ EER geral de 0.026; AVspoof 2015 $\rightarrow$ EER geral de 0; RedDots $\rightarrow$ EER geral de 0,185.
	
	\par An approach that combines speech signal analysis using \textit{Constant Q Transform} (CQT) with cepstral processing was shown in the article \cite {TODISCO2017516}. This technique results in what is called \textit{Cepstral Constant Coefficients Q}(CQCCs). According to the article, the advantage of these coefficients is the resolution of the variable time spectrum. The databases used were RedDots \cite{redDots}, SAS 2015 and AVSpoof 2015 \cite{AVSpoof2015}. In the case of classifiers, two GMMs were used, each trained using genuine data and \textit{spoofing} respectively. The tests carried out for each of the bases reached the following results: SAS 2015 $ \rightarrow $ EER overall of 0.026; AVspoof 2015 $ \rightarrow $ EER overall 0; RedDots $ \rightarrow $ EER overall 0.185.
	

	\par No artigo \cite{Patel2015} é usada a \textit{Transformação Auditiva (TU)} que tem como base a transformada \textit{wavelet}, a \textit{Cochlear Filter Cepstral Coefficients (CFCC)} é a junção dos métodos citados mais uma média dos valores em um intervalo de janela definido. Além disso, se define a \textit{estimação da frequência instantânea (IF)} que tem por base a Transformada de Hilbert\cite{johansson1999hilbert} e \cite{kschischang2006hilbert}. O processo todo tem como objetivo emular mecanismos naturais ocorridos dentro do ouvido e usa, além da \textit{TU}, o cálculo de coeficientes cepstrais e transformada cosseno. Para a composição dos vetores de características foram combinadas as técnicas \textit{MFCC}, \textit{CFCC}, \textit{CFCC+IF}. A base de dados usada foi a ASVspoof 2015. O classificador utilizado foi um GMM, as classificações chegaram uma EER de 0.083.

	\par O artigo \cite{ISI:000490497200068} propõe uma solução para distinguir sinais de voz genuínos daqueles regravados usando reverberação e as partes não vozeadas da fala. Três GMMs foram definidos para a classificação, nesta estratégia os mesmos votam se uma ocorrência é ou não verdadeira, ganhado sempre a classificação que obtiver mais votos. A base de dados utilizada foi a ASVSpoof 2017. O sistema de avaliação de desempenho escolhido, novamente, foi a ERR e esta alcançou um valor de 2,99.
	
	\par A principal ideia do artigo \cite{ISI:000465363900136} foi a de capturar a amplitude instantânea vinda de flutuações de energia para distinguir entre sinais de voz genuínos daqueles regravados. Segundo os autores, as modulações de amplitude são mais suscetíveis ao ruído inserido no sinal original por uma fonte reprodutora. O estudo usa a base de dados ASVSpoof 2017 e GMM como classificador. Os resultados apresentados chegaram a uma EER de 0.0019.

	\par No trabalho \cite{ISI:000465363900139}, foram usadas as diferenças entre bandas de frequências específicas para diferenciar um sinal legítimo de um usado em ataques de falsificação. Particularmente, foi proposta a \textit{predição linear em domínio de frequência}(FDLP) juntamente com GMMs para classificação dos dados presentes na base ASVspoof  2017. Os resultados apresentados implicam a EER de 0.0803.
	
	\par No artigo \cite{Suthokumar2018}, os autores propuseram duas novas características que visam interpretar as componentes estáticas e dinâmicas do sinal, complementando as características de tempo restrito no espectro, para distinguir entre locuções genuínas e regravadas. São elas a \textit{Modulation  Spectral Centroid Frequency} e \textit{Long Term Spectral Average}. O sistema usa como classificador um GMM juntamente com a base dados ASVSpoof 2017. Os resultados implicam o valor de EER de 0,0654.
	
	\par Considerando o envelopamento das amplitudes e  frequências instantâneas em cada banda estreita filtrada, os autores do artigo \cite{ISI:000458728700054} discutiram como diferenciar um sinal de voz legítimo de um regravado. A base de dados usada foi a  ASVSpoof 2015 e o GMM foi o classificador escolhido. A proposta alcançou a EER de 0,045.

	\par No artigo científico \cite{ISI:000392503100008}, foi proposto o uso do \textit{gammatone frequency cepstral coefficients}(MGFCC). O gammatone é o produto de uma distribuição gamma com um sinal senoidal e é usado na construção de filtros auditivos que, neste caso, são usados para extrair características do sinal de voz. A base de dados usada foi a ASVspoof 2015 e o classificador usado foi um GMM. Na distinção entre vozes genuínas e regravadas, o EER chegou a 0,02556.
	
	\par Segundo o artigo \cite{8396208}, o \textit{hashing} sensível a \textit{locus} (LSH), que é frequentemente usado como um classificador para problemas relacionados a \textit{big data}, foi combinado com coeficientes MFCCs para distinção entre locuções genuínas e regravadas. No método, os MFCCs foram extraídos dos arquivos de sinal para posterior aplicação do LSH, gerando assim uma tabela \textit{hash}. Esses valores de \textit{hash} foram então comparados, identificando assim o locutor ou locutora. Nos testes realizados houve uma acurácia de 92,66\%, a base de dados usada foi a TIMIT 2018 \cite{TIMIT2018}. 

	\par Apesar do uso de \textit{wavelets} nos artigos \cite{DiqunYan2019}, \cite{Patel2015} e \cite{7802552} é interessante notar, pelo menos até o presente momento, que seu uso é escasso em técnicas de prevenção de \textit{voice spoofing}. Em uma das abordagens mais originais como, por exemplo, a explicada em \cite{ISI:000490497200068} que usa as partes não vozeadas do sinal, seria muito útil o uso das transformadas \textit{wavelet} ou \textit{wavelet packet}. Tanto neste documento como em boa parte das referências utilizadas, é comum o uso de uma escala \textit{MEL} combinada com outras técnicas para construção do método de detecção de \textit{voice spoofing} \cite{Hanilci2018}, \cite{Patel2015}, \cite{8396208}, \cite{8725688}, \cite{ISI:000490497200068}. No entanto, em nenhuma dessas publicações se utilizou a escala \textit{BARK}, que foi, surpreendentemente, a que demonstrou  os melhores resultados no caso específico desta dissertação. O uso de coeficientes cepstrais combinados com outras técnicas foi muito comum \cite{alluri2019replay}, \cite{7802552}, \cite{8725688}, \cite{Hanilci2018}, \cite{TODISCO2017516}, \cite{Patel2015}, \cite{ISI:000392503100008}. Escolhidos os métodos de geração dos vetores de características, foram selecionados classificadores variados, com destaque para o relativamente simples \textit{Gaussian Mixture Models}(GMM), o mais escolhido. Este trabalho também contou com a escolha de dois classificadores modestos: Distância Euclidiana/Manhattam e Máquina de Vetores de Suporte.
	
	\par A leitura dos artigos mencionados nesta seção indica ainda que, aparentemente, dentro do contexto de \textit{voice spoofing}, o esforço é para se criar vetores de características cada vez melhores, sendo curioso que em nenhum dos escritos consultados houvesse uma metodologia para comparação de resultados que não fosse a manual. Nesta dissertação, existe uma série de métodos candidatos para geração dos vetores de características baseados em \textit{wavelets} e nas escalas \textit{BARK} e \textit{MEL}. Tais candidaturas foram avaliadas segundo a engenharia paraconsistente de características que selecionou a melhor combinação dentre as opções apresentadas. Em se tratando de resultados, a maioria dos trabalhos, devido ao uso das bases \textit{SAS} e \textit{AVspoof}, apresentaram seus resultados segundo a \textit{Equal Error Rate (EER)} que é a medida padrão para avaliação. Alguns outros utilizaram somente a acurácia \cite{8396208}, \cite{ISI:000473343500086}, \cite{DiqunYan2019}, \cite{Ren2019} e medidas calculadas em tabelas de confusão. Neste trabalho, todas as referidas métricas foram consideradas.